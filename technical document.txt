Please answer the following questions in the technical document. Explain why your answers are correct.


The technical document will be worth 40 marks, allocated as described above.
1.Briefly describe how your implementation works. Include information on any important algorithms, design decisions, data structures, etc. used in your implementation. [10 marks]
    Our implementation creates a new class called "node" which stores data on the node (x,y, parent, path_cost, and label[O,X,H,S, or G])
    After reading in the lines of the file and formatting it (removing any blank lines), we create a node for each object in the input and add it to a list.
    We then iterate through the list and convert any hazards and their adjacent tiles to obstacles. To do this we use the neighbourhood() function which returns all neighbours adjacent to the tile.
    Our neighbourhood function works by calling the heuristic() function with the current tile as the goal node, and finding any tiles that return a h(n) <= 1, which returns only the adjacent tiles. We skip any obstacle nodes.
    We then find the start and goal node, by iterating through our list, and storing them in a variable.
    We iterate through the list and calculate the heuristic for each node, storing it in a property on the node (node.h)
    Our heuristic function calculates the manhattan distance from each node to the goal state.
    We then call the graph_search() function, which uses code similar to what was in the lecture for A*. 
    The only difference is that after a node gets added to the frontier, the frontier is then sorted according to a key function: f(n) = node.path_cost + h(n), and reversed. Since our list pops off the end, we want the lowest f(n) to be at the end of the list, hence the reversal. 
    When our goal state is popped off the stack, we print out the Cost, Explored List, and the Optimal Path found. 

2. What type of agent have you implemented (simple reflex agent, model-based reflex agent, goal-based agent, or utility-based agent)? [3 marks]
    We have implemented a goal-based agent where the goal is to reach the goal node. 

3. What heuristic should be used for A* search for this environment? Show that this heuristic is consistent. Show that this heuristic is more informed than some alternative heuristic. [8 marks]

    http://theory.stanford.edu/~amitp/GameProgramming/Heuristics.html#manhattan-distance

4. Suggest a particular instance of this problem where A* search would find the optimal solution faster than uniform cost search. [4 marks]
    Given that movement costs are uniform it is possible that in any situation Uniform cost search could find the optimal path in the most efficient way, so I will provide an example of when it could happen. An example of when this might happen when we use this example input
    O,S,O
    O,X,O
    O,X,O
    H,O,G
    with this input A* would explore [(0,1),(0,0),(0,2),(1,2),(2,2),(3,2)] it would never explore (1,1). uniform cost search on the otherhand would very possibly visit (1,1) making it a slower search method.

5. Suggest a particular instance of this problem where a greedy heuristic search would not find the optimal solution. [4 marks]
    One example of when greedy heuristic search would not find the optimal soloution is example input 3 (I didn't copy it here because the input is very long) since our heuristic is the Manhattan-distance from the node to the goal node greedy heuristic search would take the path that goes down from the start node and would continue on that path all the way to the goal node at which point it would stop. it would achieve a path length of 38 where as the optimal is 32.

6. What strategy should be used to break ties when two nodes on the frontier have equal priority function? [3 marks]

    http://theory.stanford.edu/~amitp/GameProgramming/Heuristics.html#breaking-ties

7. Consider a variant of this problem where the agent can move to adjacent diagonal squares. What would be the best heuristic to use in A* search if the agent could also make such diagonal moves? [8 marks]
    "On a square grid that allows 8 directions of movement, use Diagonal distance (Lâˆž)....
    http://theory.stanford.edu/~amitp/GameProgramming/Heuristics.html#diagonal-distance